{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbe3a5c",
   "metadata": {},
   "source": [
    "# Training the CF explainer and getting a CF example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b6a949",
   "metadata": {},
   "source": [
    "Note: this code is very similar (and the same in many places) to the other two training processes, however, this one uses the GCN from the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4eda57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janneke/opt/anaconda3/envs/CF-GNNExplainer/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# first import the needed packages\n",
    "import torch\n",
    "import numpy as np\n",
    "from gcn import *\n",
    "from gcn_perturbation_matrix import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from explainer_framework import *\n",
    "from calculate_metrics import *\n",
    "from models_original_paper.gcn import GCNSynthetic as GCN_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4124c8",
   "metadata": {},
   "source": [
    "### Read in the data we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb28c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/syn1.pickle','rb') as pickle_file: \n",
    "    data_syn1 = pickle.load(pickle_file)\n",
    "\n",
    "with open('data/syn4.pickle','rb') as pickle_file:\n",
    "    data_syn4 = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/syn5.pickle','rb') as pickle_file:\n",
    "    data_syn5 = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02df5e",
   "metadata": {},
   "source": [
    "### Put data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0440312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze the labels (as it has a singleton dim and then make it a tensor)\n",
    "labels_syn1 = np.squeeze(data_syn1['labels'])\n",
    "labels_syn1 = torch.tensor(labels_syn1)\n",
    "\n",
    "labels_syn4 = np.squeeze(data_syn4['labels'])\n",
    "labels_syn4 = torch.tensor(labels_syn4)\n",
    "\n",
    "labels_syn5 = np.squeeze(data_syn5['labels'])\n",
    "labels_syn5 = torch.tensor(labels_syn5)\n",
    "\n",
    "# same for features, but define the type of data here\n",
    "features_syn1 = np.squeeze(data_syn1['feat'])\n",
    "features_syn1 = torch.tensor(features_syn1, dtype=torch.float)\n",
    "\n",
    "features_syn4 = np.squeeze(data_syn4['feat'])\n",
    "features_syn4 = torch.tensor(features_syn4, dtype=torch.float)\n",
    "\n",
    "features_syn5 = np.squeeze(data_syn5['feat'])\n",
    "features_syn5 = torch.tensor(features_syn5, dtype=torch.float)\n",
    "\n",
    "# adjacency matrix\n",
    "adjacency_matrix_syn1 = torch.tensor(np.squeeze(data_syn1['adj']), dtype=torch.float)\n",
    "adjacency_matrix_syn4 = torch.tensor(np.squeeze(data_syn4['adj']), dtype=torch.float)\n",
    "adjacency_matrix_syn5 = torch.tensor(np.squeeze(data_syn5['adj']), dtype=torch.float)\n",
    "\n",
    "# the indices are already a list --> but have to split the training data in training and validation data first\n",
    "train_indices_full_syn1 = torch.tensor(data_syn1['train_idx'])\n",
    "train_indices_full_syn4 = torch.tensor(data_syn4['train_idx'])\n",
    "train_indices_full_syn5 = torch.tensor(data_syn5['train_idx'])\n",
    "\n",
    "# split in training and validation indices\n",
    "train_indices_syn1, validation_indices_syn1 = torch.utils.data.random_split(train_indices_full_syn1, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "train_indices_syn4, validation_indices_syn4 = torch.utils.data.random_split(train_indices_full_syn4, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "train_indices_syn5, validation_indices_syn5 = torch.utils.data.random_split(train_indices_full_syn5, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "test_indices_syn1 = torch.tensor(data_syn1['test_idx'])\n",
    "test_indices_syn4 = torch.tensor(data_syn4['test_idx'])\n",
    "test_indices_syn5 = torch.tensor(data_syn5['test_idx'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f0192",
   "metadata": {},
   "source": [
    "### Get the original models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23dd93b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_syn1_dict = torch.load('models_original_paper/gcn_3layer_syn1.pt')\n",
    "model_syn4_dict = torch.load('models_original_paper/gcn_3layer_syn4.pt')\n",
    "model_syn5_dict = torch.load('models_original_paper/gcn_3layer_syn5.pt')\n",
    "\n",
    "model_syn1 = GCN_original(nfeat=model_syn1_dict['gc1.weight'].shape[0], nhid=model_syn1_dict['gc1.weight'].shape[1], nout=model_syn1_dict['gc1.weight'].shape[1], nclass=model_syn1_dict['lin.bias'].shape[0], dropout=0)\n",
    "model_syn1.load_state_dict(model_syn1_dict)\n",
    "\n",
    "model_syn4 = GCN_original(nfeat=model_syn4_dict['gc1.weight'].shape[0], nhid=model_syn4_dict['gc1.weight'].shape[1], nout=model_syn4_dict['gc1.weight'].shape[1], nclass=model_syn4_dict['lin.bias'].shape[0], dropout=0)\n",
    "model_syn4.load_state_dict(model_syn4_dict)\n",
    "\n",
    "model_syn5 = GCN_original(nfeat=model_syn5_dict['gc1.weight'].shape[0], nhid=model_syn5_dict['gc1.weight'].shape[1], nout=model_syn5_dict['gc1.weight'].shape[1], nclass=model_syn5_dict['lin.bias'].shape[0], dropout=0)\n",
    "model_syn5.load_state_dict(model_syn5_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6821b9",
   "metadata": {},
   "source": [
    "### First, get the original predictions for the model we're researching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b854dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of Syn1 data:  0.9857142857142858\n",
      "Test accuracy of Syn4 data:  0.9085714285714286\n",
      "Test accuracy of Syn5 data:  0.8744939271255061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janneke/Documents/GitHub/CF-GNNExplainer-recreation/gcn.py:147: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525473998/work/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  A_hat = torch.sparse_coo_tensor((A_hat.row, A_hat.col), A_hat.data, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "model_syn1.eval()\n",
    "sparse_adj_1 = get_sparse_adjacency_normalized(features_syn1.shape[0], adjacency_matrix_syn1)\n",
    "outputs_syn1 = model_syn1(features_syn1, sparse_adj_1)\n",
    "\n",
    "# print accuracy too (to check that it is the same as in the original)\n",
    "_, predictions_1 = torch.max(outputs_syn1.data, 1)\n",
    "print(\"Test accuracy of Syn1 data: \", accuracy_score(labels_syn1[test_indices_syn1], predictions_1[test_indices_syn1]))\n",
    "\n",
    "model_syn4.eval()\n",
    "sparse_adj_4 = get_sparse_adjacency_normalized(features_syn4.shape[0], adjacency_matrix_syn4)\n",
    "outputs_syn4 = model_syn4(features_syn4, sparse_adj_4)\n",
    "\n",
    "# print accuracy too (to check that it is the same as in the original)\n",
    "_, predictions_4 = torch.max(outputs_syn4.data, 1)\n",
    "print(\"Test accuracy of Syn4 data: \", accuracy_score(labels_syn4[test_indices_syn4], predictions_4[test_indices_syn4]))\n",
    "\n",
    "model_syn5.eval()\n",
    "sparse_adj_5 = get_sparse_adjacency_normalized(features_syn5.shape[0], adjacency_matrix_syn5)\n",
    "outputs_syn5 = model_syn5(features_syn5, sparse_adj_5)\n",
    "\n",
    "# print accuracy too (to check that it is the same as in the original)\n",
    "_, predictions_5 = torch.max(outputs_syn5.data, 1)\n",
    "print(\"Test accuracy of Syn5 data: \", accuracy_score(labels_syn5[test_indices_syn5], predictions_5[test_indices_syn5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92caf2d",
   "metadata": {},
   "source": [
    "### Get the weights and biases for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa872c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_W_syn1 = model_syn1_dict['gc1.weight'].detach()\n",
    "layer1_b_syn1 = model_syn1_dict['gc1.bias'].detach()\n",
    "layer2_W_syn1 = model_syn1_dict['gc2.weight'].detach()\n",
    "layer2_b_syn1 = model_syn1_dict['gc2.bias'].detach()\n",
    "layer3_W_syn1 = model_syn1_dict['gc3.weight'].detach()\n",
    "layer3_b_syn1 = model_syn1_dict['gc3.bias'].detach()\n",
    "lin_weight_syn1 = model_syn1_dict['lin.weight'].detach()\n",
    "lin_b_syn1 = model_syn1_dict['lin.bias'].detach()\n",
    "\n",
    "layer1_W_syn4 = model_syn4_dict['gc1.weight'].detach()\n",
    "layer1_b_syn4 = model_syn4_dict['gc1.bias'].detach()\n",
    "layer2_W_syn4 = model_syn4_dict['gc2.weight'].detach()\n",
    "layer2_b_syn4 = model_syn4_dict['gc2.bias'].detach()\n",
    "layer3_W_syn4 = model_syn4_dict['gc3.weight'].detach()\n",
    "layer3_b_syn4 = model_syn4_dict['gc3.bias'].detach()\n",
    "lin_weight_syn4 = model_syn4_dict['lin.weight'].detach()\n",
    "lin_b_syn4 = model_syn4_dict['lin.bias'].detach()\n",
    "\n",
    "layer1_W_syn5 = model_syn5_dict['gc1.weight'].detach()\n",
    "layer1_b_syn5 = model_syn5_dict['gc1.bias'].detach()\n",
    "layer2_W_syn5 = model_syn5_dict['gc2.weight'].detach()\n",
    "layer2_b_syn5 = model_syn5_dict['gc2.bias'].detach()\n",
    "layer3_W_syn5 = model_syn5_dict['gc3.weight'].detach()\n",
    "layer3_b_syn5 = model_syn5_dict['gc3.bias'].detach()\n",
    "lin_weight_syn5 = model_syn5_dict['lin.weight'].detach()\n",
    "lin_b_syn5 = model_syn5_dict['lin.bias'].detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789b2e9",
   "metadata": {},
   "source": [
    "### Set up structure to get CF-examples (new perturbed GCN for every node we get a CF-explanation for!)\n",
    "As subgraphs may have different sizes--> first get subgraph, then we know how big the perturbation matrix should be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcb671",
   "metadata": {},
   "source": [
    "## Train it and get the CF-examples - Syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accef3aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janneke/Documents/GitHub/CF-GNNExplainer-recreation/gcn_perturbation_matrix.py:187: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nll_loss_part = nll_loss(F.log_softmax(output_g), target=prediction_original)\n"
     ]
    }
   ],
   "source": [
    "examples_all_syn1 = []\n",
    "train_loss_all_syn1 = []\n",
    "adjacency_neigh_syn1 = []\n",
    "mapping_syn1 = []\n",
    "nr_cf_syn1 = 0\n",
    "\n",
    "for index in test_indices_syn1: \n",
    "    # get the old prediction\n",
    "    old_prediction = predictions_1[index.item()]\n",
    "    \n",
    "    # get the subgraph neighbourhood\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index.item(), 4, labels_syn1, features_syn1, adjacency_matrix_syn1)\n",
    "    \n",
    "    new_index = vertex_mapping[index.item()]\n",
    "    \n",
    "    # test whether it gets the same outcome\n",
    "    sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model_syn1(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # get accuracy too (to check that it is the same as in the original)\n",
    "    _, predictions_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    # as a small test:\n",
    "    assert predictions_test[new_index].item() == old_prediction, \"wrong prediction\"\n",
    "        \n",
    "    # make a gcn model (to use for perturbation):\n",
    "    model_pert = GCNPerturbed(layer1_W_syn1, layer1_b_syn1, layer2_W_syn1, layer2_b_syn1, layer3_W_syn1, layer3_b_syn1, lin_weight_syn1, lin_b_syn1, adjacency_matrix.shape[0])\n",
    "    \n",
    "    # from the model hyperparams:\n",
    "    alpha = 0.1\n",
    "    optim = torch.optim.SGD(model_pert.parameters(), lr=alpha, nesterov=True, momentum=0.9)\n",
    "    beta = 0.5\n",
    "    k = 500\n",
    "    \n",
    "    # get the new cf example!\n",
    "    examples_for_index, train_loss = get_cf_example(new_index, old_prediction, model_pert, optim, beta, k, adjacency_matrix, labels_perturbed, features_perturbed)\n",
    "    \n",
    "    # append to all examples!!\n",
    "    examples_all_syn1.append(examples_for_index)\n",
    "    train_loss_all_syn1.append(train_loss)\n",
    "    adjacency_neigh_syn1.append(adjacency_matrix)\n",
    "    mapping_syn1.append(vertex_mapping)\n",
    "    \n",
    "    # add one if a counterfactual example was found for this index\n",
    "    if examples_for_index != []:\n",
    "        nr_cf_syn1 = nr_cf_syn1 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c227627",
   "metadata": {},
   "source": [
    "## Train it and get the CF-examples - Syn4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8777fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_all_syn4 = []\n",
    "train_loss_all_syn4 = []\n",
    "adjacency_neigh_syn4 = []\n",
    "mapping_syn4 = []\n",
    "nr_cf_syn4 = 0\n",
    "\n",
    "for index in test_indices_syn4: \n",
    "    # get the old prediction\n",
    "    old_prediction = predictions_4[index.item()]\n",
    "    \n",
    "    # get the subgraph neighbourhood\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index.item(), 4, labels_syn4, features_syn4, adjacency_matrix_syn4)\n",
    "    \n",
    "    new_index = vertex_mapping[index.item()]\n",
    "    \n",
    "    # test whether it gets the same outcome\n",
    "    sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model_syn4(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # get accuracy too (to check that it is the same as in the original)\n",
    "    _, predictions_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    # as a small test:\n",
    "    assert predictions_test[new_index].item() == old_prediction, \"wrong prediction\"\n",
    "        \n",
    "    # make a gcn model (to use for perturbation):\n",
    "    model_pert = GCNPerturbed(layer1_W_syn4, layer1_b_syn4, layer2_W_syn4, layer2_b_syn4, layer3_W_syn4, layer3_b_syn4, lin_weight_syn4, lin_b_syn4, adjacency_matrix.shape[0])\n",
    "    \n",
    "    # from the model hyperparams:\n",
    "    alpha = 0.1\n",
    "    optim = torch.optim.SGD(model_pert.parameters(), lr=alpha)\n",
    "    beta = 0.5\n",
    "    k = 500\n",
    "    \n",
    "    # get the new cf example!\n",
    "    examples_for_index, train_loss = get_cf_example(new_index, old_prediction, model_pert, optim, beta, k, adjacency_matrix, labels_perturbed, features_perturbed)\n",
    "    \n",
    "    # append to all examples!!\n",
    "    examples_all_syn4.append(examples_for_index)\n",
    "    train_loss_all_syn4.append(train_loss)\n",
    "    adjacency_neigh_syn4.append(adjacency_matrix)\n",
    "    mapping_syn4.append(vertex_mapping)\n",
    "    \n",
    "    # add one if a counterfactual example was found for this index\n",
    "    if examples_for_index != []:\n",
    "        nr_cf_syn4 = nr_cf_syn4 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a281e75",
   "metadata": {},
   "source": [
    "## Train it and get the CF-examples - Syn5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13356086",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_all_syn5 = []\n",
    "train_loss_all_syn5 = []\n",
    "nr_cf_syn5 = 0\n",
    "adjacency_neigh_syn5 = []\n",
    "mapping_syn5 = []\n",
    "\n",
    "for index in test_indices_syn5: \n",
    "    # get the old prediction\n",
    "    old_prediction = predictions_5[index.item()]\n",
    "    \n",
    "    # get the subgraph neighbourhood\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index.item(), 4, labels_syn5, features_syn5, adjacency_matrix_syn5)\n",
    "    \n",
    "    new_index = vertex_mapping[index.item()]\n",
    "    \n",
    "    # test whether it gets the same outcome\n",
    "    sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model_syn5(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # get accuracy too (to check that it is the same as in the original)\n",
    "    _, predictions_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    # as a small test:\n",
    "    assert predictions_test[new_index].item() == old_prediction, \"wrong prediction\"\n",
    "        \n",
    "    # make a gcn model (to use for perturbation):\n",
    "    model_pert = GCNPerturbed(layer1_W_syn5, layer1_b_syn5, layer2_W_syn5, layer2_b_syn5, layer3_W_syn5, layer3_b_syn5, lin_weight_syn5, lin_b_syn5, adjacency_matrix.shape[0])\n",
    "    \n",
    "    # from the model hyperparams:\n",
    "    alpha = 0.1\n",
    "    optim = torch.optim.SGD(model_pert.parameters(), lr=alpha)\n",
    "    beta = 0.5\n",
    "    k = 500\n",
    "    \n",
    "    # get the new cf example!\n",
    "    examples_for_index, train_loss = get_cf_example(new_index, old_prediction, model_pert, optim, beta, k, adjacency_matrix, labels_perturbed, features_perturbed)\n",
    "    \n",
    "    # append to all examples!!\n",
    "    examples_all_syn5.append(examples_for_index)\n",
    "    train_loss_all_syn5.append(train_loss)\n",
    "    adjacency_neigh_syn5.append(adjacency_matrix)\n",
    "    mapping_syn5.append(vertex_mapping)\n",
    "    \n",
    "    # add one if a counterfactual example was found for this index\n",
    "    if examples_for_index != []:\n",
    "        nr_cf_syn5 = nr_cf_syn5 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c69f5a",
   "metadata": {},
   "source": [
    "## Get the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e650207",
   "metadata": {},
   "source": [
    "### Syn 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dde694e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn1, mean sparsity: 0.9880629164070579\n",
      "Syn1, fidelity: 0.1785714285714286\n",
      "Syn1, mean accuracy: 0.9935897435897436\n",
      "Syn1, mean explanation size: 2.0869565217391304\n",
      "Syn1, std sparsity: 0.0216379374997368\n",
      "Syn1, std accuracy: 0.05661385170722979\n",
      "Syn1, std explanation size: 2.230432329232618\n"
     ]
    }
   ],
   "source": [
    "sparsity_mean, sparsity_std = sparsity(adjacency_neigh_syn1, examples_all_syn1)\n",
    "fidelity_syn1 = fidelity(len(test_indices_syn1), nr_cf_syn1)\n",
    "accuracy_syn1, accuracy_syn1_std = accuracy_explanation(test_indices_syn1, predictions_1, adjacency_neigh_syn1, examples_all_syn1, mapping_syn1)\n",
    "explanation_size_mean, explanation_size_std, explanation_size_list_syn1 = explanation_size(examples_all_syn1, adjacency_neigh_syn1)\n",
    "\n",
    "print(\"Syn1, mean sparsity:\", sparsity_mean)\n",
    "print(\"Syn1, fidelity:\", fidelity_syn1)\n",
    "print(\"Syn1, mean accuracy:\", accuracy_syn1)\n",
    "print(\"Syn1, mean explanation size:\", explanation_size_mean)\n",
    "\n",
    "print(\"Syn1, std sparsity:\", sparsity_std)\n",
    "print(\"Syn1, std accuracy:\", accuracy_syn1_std)\n",
    "print(\"Syn1, std explanation size:\", explanation_size_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d6252",
   "metadata": {},
   "source": [
    "### Syn 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3876334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn4, mean sparsity: 0.916360701158129\n",
      "Syn4, fidelity: 0.17142857142857137\n",
      "Syn4, mean accuracy: 0.9509803921568627\n",
      "Syn4, mean explanation size: 1.5655172413793104\n",
      "Syn4, std sparsity: 0.04909336212398611\n",
      "Syn4, std accuracy: 0.20627413703090153\n",
      "Syn4, std explanation size: 1.1535801343802612\n"
     ]
    }
   ],
   "source": [
    "sparsity_mean, sparsity_std = sparsity(adjacency_neigh_syn4, examples_all_syn4)\n",
    "fidelity_syn4 = fidelity(len(test_indices_syn4), nr_cf_syn4)\n",
    "accuracy_syn4, accuracy_syn4_std = accuracy_explanation(test_indices_syn4, predictions_4, adjacency_neigh_syn4, examples_all_syn4, mapping_syn4 )\n",
    "explanation_size_mean, explanation_size_std, explanation_size_list_syn4 = explanation_size(examples_all_syn4, adjacency_neigh_syn4)\n",
    "\n",
    "print(\"Syn4, mean sparsity:\", sparsity_mean)\n",
    "print(\"Syn4, fidelity:\", fidelity_syn4)\n",
    "print(\"Syn4, mean accuracy:\", accuracy_syn4)\n",
    "print(\"Syn4, mean explanation size:\", explanation_size_mean)\n",
    "\n",
    "print(\"Syn4, std sparsity:\", sparsity_std)\n",
    "print(\"Syn4, std accuracy:\", accuracy_syn4_std)\n",
    "print(\"Syn4, std explanation size:\", explanation_size_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79454034",
   "metadata": {},
   "source": [
    "### Syn 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44c7488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn5, mean sparsity: 0.9469845265236888\n",
      "Syn5, fidelity: 0.04453441295546556\n",
      "Syn5, mean accuracy: 0.9113475177304965\n",
      "Syn5, mean explanation size: 1.3305084745762712\n",
      "Syn5, std sparsity: 0.04171070244423978\n",
      "Syn5, std accuracy: 0.28210742598762933\n",
      "Syn5, std explanation size: 0.7211702634357896\n"
     ]
    }
   ],
   "source": [
    "sparsity_mean, sparsity_std = sparsity(adjacency_neigh_syn5, examples_all_syn5)\n",
    "fidelity_syn5 = fidelity(len(test_indices_syn5), nr_cf_syn5)\n",
    "accuracy_syn5, accuracy_syn5_std = accuracy_explanation(test_indices_syn5, predictions_5, adjacency_neigh_syn5, examples_all_syn5, mapping_syn5 )\n",
    "explanation_size_mean, explanation_size_std, explanation_size_list_syn5 = explanation_size(examples_all_syn5, adjacency_neigh_syn5)\n",
    "\n",
    "print(\"Syn5, mean sparsity:\", sparsity_mean)\n",
    "print(\"Syn5, fidelity:\", fidelity_syn5)\n",
    "print(\"Syn5, mean accuracy:\", accuracy_syn5)\n",
    "print(\"Syn5, mean explanation size:\", explanation_size_mean)\n",
    "\n",
    "print(\"Syn5, std sparsity:\", sparsity_std)\n",
    "print(\"Syn5, std accuracy:\", accuracy_syn5_std)\n",
    "print(\"Syn5, std explanation size:\", explanation_size_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbef58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFGNNExplainerKernel",
   "language": "python",
   "name": "cfgnnexplainerkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
