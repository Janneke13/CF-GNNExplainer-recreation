{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972264d5",
   "metadata": {},
   "source": [
    "# Trying to perturb some data and find a perturbation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c171d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0528bc5",
   "metadata": {},
   "source": [
    "### Create fixed layer class (fixed params) and a perturbed gcn (adds p_hat as a param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fadde73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayerFixed(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of a GCN layer, with already fixed weight matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weight_matrix, bias):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(weight_matrix, requires_grad=False)\n",
    "        self.b = torch.nn.Parameter(bias, requires_grad=False)\n",
    "\n",
    "    def forward(self, X, A_hat):\n",
    "        # perform one forward pass and add bias\n",
    "        temp = torch.spmm(A_hat, X)\n",
    "        Z = torch.spmm(temp, self.W) + self.b\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d66d3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNPerturbed(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of a GCN, but with a perturbation matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, W1, b1, W2, b2, W3, b3, wl, bl, number_neighbour_nodes):\n",
    "        super().__init__()\n",
    "        # three GCN layers (using the module that was used before)\n",
    "        self.gcn_layer_1 = GCNLayerFixed(W1, b1)\n",
    "        self.gcn_layer_2 = GCNLayerFixed(W2, b2)\n",
    "        self.gcn_layer_3 = GCNLayerFixed(W3, b3)\n",
    "        self.linear_layer = torch.nn.Linear(wl.shape[1], wl.shape[0])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.linear_layer.weight.copy_(wl)\n",
    "            self.linear_layer.bias.copy_(bl)\n",
    "            \n",
    "        self.linear_layer.weight.requires_grad=False\n",
    "        self.linear_layer.bias.requires_grad=False\n",
    "            \n",
    "        size_vector = int(number_neighbour_nodes* (number_neighbour_nodes + 1) / 2)\n",
    "        self.p_hat = torch.nn.Parameter(torch.ones(size_vector, requires_grad=True))\n",
    "\n",
    "    # this is similar to the original GCN, but now uses the perturbation matrix as well \n",
    "    # --> also only uses slices of the original adjacency matrix --> for both X and A these slices are defined before!\n",
    "    def forward(self, X, A):\n",
    "        # first, get the perturbation matrix (binary)\n",
    "        pert = torch.sigmoid(self.p_hat)\n",
    "        pert = (pert>0.5).float()\n",
    "        \n",
    "        # populate the matrix symmetrically!! --> diagonal should not matter, but keep it 1 for now\n",
    "        index_row, index_col = torch.triu_indices(A.shape[0], A.shape[0]) # A.shape[0] stands for the nr of nodes\n",
    "        \n",
    "        # populate the matrix symmetrically \n",
    "        P = torch.zeros(A.shape[0], A.shape[0])\n",
    "        P[index_row, index_col] = pert\n",
    "        P.T[index_row, index_col] = pert\n",
    "        \n",
    "        # now, multiply this one (element-wise) with the adjacency matrix\n",
    "        a_pert = torch.mul(P, A) \n",
    "        \n",
    "        # now, normalize A (we can use the function defined for the basic GCN)\n",
    "        A_hat = get_sparse_adjacency_normalized(X.shape[0], A)\n",
    "        \n",
    "        # perform three forward passes for the GCN layers:\n",
    "        h_1 = self.gcn_layer_1.forward(X, A_hat)\n",
    "        h_1_relu = F.relu(h_1)\n",
    "        h_2 = self.gcn_layer_2.forward(h_1_relu, A_hat)\n",
    "        h_2_relu = F.relu(h_2)\n",
    "        h_3 = self.gcn_layer_3.forward(h_2_relu, A_hat)\n",
    "\n",
    "        # create the input for the linear layer\n",
    "        in_lin = torch.cat((h_1, h_2, h_3), dim=1)\n",
    "\n",
    "        # perform the last linear layer\n",
    "        output = self.linear_layer(in_lin)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c7de675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/syn1model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42295216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get parameters:\n",
    "layer1_W = model.gcn_layer_1.W.detach()\n",
    "layer1_b = model.gcn_layer_1.b.detach()\n",
    "layer2_W = model.gcn_layer_2.W.detach()\n",
    "layer2_b = model.gcn_layer_2.b.detach()\n",
    "layer3_W = model.gcn_layer_3.W.detach()\n",
    "layer3_b = model.gcn_layer_3.b.detach()\n",
    "lin_weight = model.linear_layer.weight.detach()\n",
    "lin_b = model.linear_layer.bias.detach()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e6bab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GCNPerturbed(layer1_W, layer1_b, layer2_W, layer2_b, layer3_W, layer3_b, lin_weight, lin_b, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86b53d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_hat Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True)\n",
      "gcn_layer_1.W Parameter containing:\n",
      "tensor([[ 0.0865,  0.1236,  0.1730,  0.2322,  0.1943, -0.2290,  0.0777,  0.4368,\n",
      "          0.9785, -0.3618,  0.7307,  0.0976,  0.6974,  0.1414,  0.0540, -0.2375,\n",
      "          0.7264,  0.1002, -0.1073, -0.1769],\n",
      "        [-0.3543, -0.2643,  0.0929,  0.1197, -0.0842, -0.4696,  0.1793, -0.1287,\n",
      "          0.6226, -0.4546,  0.7469, -0.3461,  0.7135,  0.1564, -0.2632,  0.1015,\n",
      "          0.4333,  0.4224,  0.1918, -0.4318],\n",
      "        [-0.0984, -0.3257,  0.4756,  0.2208,  0.5802, -0.4612,  0.6042,  0.2468,\n",
      "          0.8124, -0.3166, -0.1769, -0.1469, -0.0383,  0.4748, -0.0231,  0.0100,\n",
      "          0.5099,  0.0196,  0.5410, -0.6062],\n",
      "        [-0.1724, -0.4878,  0.4240, -0.3183,  0.4491, -0.3797,  0.7282, -0.1245,\n",
      "          0.2937, -0.3118,  0.7451,  0.1596,  0.8058, -0.3233, -0.5218, -0.5207,\n",
      "          0.0348,  0.2257,  0.3209,  0.0845],\n",
      "        [-0.3731, -0.4875,  0.5259, -0.3440,  0.5941, -0.3901,  0.6016, -0.2153,\n",
      "          0.3381,  0.0182,  0.4138, -0.0908,  0.6281,  0.4061, -0.4185, -0.4112,\n",
      "          0.7951, -0.1366, -0.0490, -0.7187],\n",
      "        [-0.3921, -0.1162,  0.2205, -0.4821,  0.3121, -0.5471, -0.1024, -0.1039,\n",
      "          0.1577, -0.3265,  0.7929,  0.0983,  0.4880, -0.3753, -0.3921, -0.3224,\n",
      "          0.4335, -0.4023, -0.0886, -0.5570],\n",
      "        [-0.1938, -0.3657,  0.2496, -0.4614, -0.0337, -0.5125,  0.1495, -0.2214,\n",
      "          0.9597, -0.1668,  0.7265,  0.1504, -0.0775,  0.4120, -0.2439, -0.3447,\n",
      "         -0.0414, -0.4583,  0.2836, -0.3888],\n",
      "        [-0.0543, -0.5417,  0.6227, -0.4856,  0.2169, -0.2263,  0.5742,  0.5373,\n",
      "          0.9913, -0.3834,  0.4333, -0.1657,  0.2841, -0.2862,  0.2263, -0.4994,\n",
      "          0.6140,  0.1996,  0.3037, -0.5314],\n",
      "        [ 0.1422, -0.1284,  0.3411, -0.5486,  0.5039, -0.3587,  0.0920,  0.5607,\n",
      "          0.6823, -0.2961,  0.0627, -0.0024,  0.6097, -0.0479, -0.3587, -0.3267,\n",
      "         -0.0012,  0.2021,  0.5366, -0.7073],\n",
      "        [-0.1116, -0.0069,  0.3655, -0.3233,  0.5531, -0.1049,  0.5040,  0.0781,\n",
      "          0.4531, -0.0549,  0.2246, -0.1092,  0.6490,  0.4938, -0.1752, -0.2742,\n",
      "          0.3656, -0.0010,  0.2598, -0.1655]])\n",
      "gcn_layer_1.b Parameter containing:\n",
      "tensor([ 0.5644, -0.3678, -0.5754, -0.4553, -0.0250, -0.5537, -0.3715, -1.0174,\n",
      "        -0.7214,  0.0304, -0.5778,  0.3387, -0.1466, -1.0034,  0.5239, -0.1469,\n",
      "        -0.3220,  0.6757, -0.1882,  0.2171])\n",
      "gcn_layer_2.W Parameter containing:\n",
      "tensor([[-1.1776e-01, -2.1870e-02,  1.8732e-01,  1.3029e-01, -1.7235e-02,\n",
      "         -1.0819e-01, -2.4584e-02, -1.3429e-01, -7.0969e-02,  9.8881e-02,\n",
      "          1.6132e-01,  3.8229e-02, -2.4645e-01, -2.5197e-01, -4.4517e-02,\n",
      "          4.8471e-02,  1.4953e-02, -3.0467e-02,  5.2919e-02, -1.8341e-02],\n",
      "        [-7.3826e-04,  2.4407e-03, -3.4610e-06, -6.3065e-21, -2.2836e-02,\n",
      "          1.0544e-03,  3.3862e-03,  8.3581e-09, -1.5907e-03, -2.1816e-02,\n",
      "         -5.9415e-03,  2.9526e-03,  1.0125e-05,  7.7443e-03,  4.5381e-05,\n",
      "         -1.0690e-17,  3.6326e-26, -3.4968e-03, -8.8115e-03, -1.5797e-02],\n",
      "        [ 1.8302e-01,  3.8708e-02, -2.9579e-01, -2.6910e-01, -1.4697e-01,\n",
      "         -3.7177e-01, -3.7906e-01,  1.8329e-01, -2.4517e-01,  1.7410e-01,\n",
      "         -4.1913e-01, -1.7822e-01, -1.8857e-01, -2.1960e-01,  8.4102e-03,\n",
      "         -5.8105e-01,  1.0541e-01, -9.0440e-02,  7.7399e-02,  7.0248e-02],\n",
      "        [ 2.0051e-03, -3.7584e-03,  2.1328e-03, -7.5539e-06,  1.5687e-08,\n",
      "          1.6197e-02,  3.0755e-23,  1.2860e-26,  5.4416e-19, -7.3158e-03,\n",
      "          1.0045e-05, -2.2562e-02,  4.5996e-04,  3.0408e-03,  1.6913e-02,\n",
      "          1.9806e-18, -6.4886e-03,  3.5832e-19,  1.0101e-04, -2.2902e-02],\n",
      "        [ 1.1055e-03, -3.8012e-02, -2.6462e-01, -1.8950e-01, -2.0526e-01,\n",
      "         -2.3714e-01, -4.3655e-01,  3.3750e-01,  1.7346e-01, -2.0467e-01,\n",
      "         -3.7880e-01, -1.7737e-02, -4.8191e-01, -3.7217e-01,  3.1370e-01,\n",
      "         -4.3692e-01, -3.3307e-01,  1.9956e-01, -2.3015e-01, -9.0662e-02],\n",
      "        [ 2.7660e-26,  6.5228e-20, -8.8299e-10, -9.6231e-06, -6.0345e-03,\n",
      "          7.5453e-03, -1.5994e-07, -7.9238e-17, -1.2292e-09, -1.0227e-24,\n",
      "          1.5478e-02,  4.5371e-06, -9.5468e-03,  1.2688e-07,  1.7304e-02,\n",
      "         -1.4490e-16,  1.0733e-03,  2.1681e-02,  7.0576e-23,  7.2818e-21],\n",
      "        [-1.3706e-01,  2.1611e-01,  4.0586e-02,  2.6303e-01, -3.3869e-01,\n",
      "         -3.6798e-01, -3.5043e-01, -2.3549e-01, -4.0619e-01, -2.4168e-01,\n",
      "         -3.6685e-02,  1.3095e-01, -4.1733e-01, -2.7084e-01,  4.0404e-01,\n",
      "         -4.8545e-01, -1.7825e-01,  5.0297e-01, -2.4866e-01, -4.5663e-02],\n",
      "        [-7.6013e-01,  1.1139e+00,  5.4976e-01, -1.5853e+00, -1.5697e+00,\n",
      "          3.8703e-01,  5.8474e-01,  5.8387e-01,  4.5469e-01,  7.3909e-01,\n",
      "          9.3151e-01,  4.4383e-02,  6.2769e-01,  1.6852e-02,  2.0660e-01,\n",
      "          7.7617e-01,  4.4639e-01,  1.1442e+00,  5.1648e-01,  1.9587e-01],\n",
      "        [-7.8873e-02,  5.3116e-02, -6.5470e-01,  3.8869e-02,  1.4378e-01,\n",
      "         -7.0793e-02, -1.6380e-01, -2.1347e-01, -5.6136e-01, -1.3646e-01,\n",
      "          1.2726e-01,  3.0408e-01, -4.0748e-01, -3.2837e-02, -1.0282e-01,\n",
      "         -4.7728e-01, -7.4461e-02,  5.8867e-01,  1.8262e-01, -2.9725e-01],\n",
      "        [ 1.0437e-03, -1.7757e-03,  2.1308e-08,  8.0661e-03, -1.2153e-25,\n",
      "          1.3244e-02, -8.4719e-03, -4.0366e-08,  2.1247e-04, -3.5598e-21,\n",
      "         -2.2619e-20, -4.6961e-07,  1.4213e-03,  1.4984e-05,  2.0852e-11,\n",
      "         -1.2868e-04, -5.9174e-03,  3.9811e-24, -1.1270e-13, -4.7386e-06],\n",
      "        [-1.0653e-01,  6.4152e-01, -1.4724e-01,  4.1392e-02, -1.8460e-01,\n",
      "         -4.8991e-01, -5.4218e-01, -1.7314e-01, -3.4968e-01,  5.3286e-02,\n",
      "         -3.9123e-01, -9.5971e-02,  3.6480e-01,  1.7600e-01,  4.6515e-01,\n",
      "         -4.5670e-01, -2.9414e-01,  4.4174e-01, -3.8977e-01, -2.4798e-01],\n",
      "        [-2.3919e-01,  5.5732e-01,  1.3100e-01, -5.5882e-01, -5.4919e-01,\n",
      "          1.0673e-01,  1.3662e-01,  4.0306e-01,  9.1612e-02,  1.4646e-01,\n",
      "          3.0202e-01,  5.2123e-02,  1.0376e-01,  4.3963e-02,  3.2066e-02,\n",
      "          1.1657e-01,  5.7640e-02,  6.3129e-01,  1.7362e-01,  7.2770e-02],\n",
      "        [-1.1262e-01,  6.2806e-01, -1.9973e-01,  4.3716e-01,  4.6360e-01,\n",
      "         -3.0496e-01, -4.4858e-01,  3.9831e-01,  2.5289e-01, -4.8287e-01,\n",
      "         -2.8550e-01, -3.2114e-01, -4.9423e-01,  9.5651e-02,  2.3828e-01,\n",
      "         -1.7783e-01, -2.3091e-01,  6.9451e-01, -4.7870e-02, -2.2140e-01],\n",
      "        [-6.4585e-01,  1.2892e+00,  6.0281e-01, -1.4400e+00, -1.0912e+00,\n",
      "          2.5026e-01,  3.6445e-01,  6.0045e-01,  5.6488e-01,  6.8813e-01,\n",
      "          1.0665e+00,  5.3948e-02,  5.6544e-01, -6.1275e-02,  1.0347e-01,\n",
      "          7.6684e-01,  2.9901e-01,  8.1703e-01,  4.3838e-01,  1.7604e-01],\n",
      "        [ 3.4267e-05, -6.7480e-08, -2.3895e-04,  1.9487e-23, -2.4351e-04,\n",
      "         -7.8696e-04,  4.1908e-05,  3.6434e-23,  1.3623e-02,  2.0048e-02,\n",
      "         -1.3223e-13,  8.6581e-10, -5.6115e-19, -8.9153e-26, -2.5277e-25,\n",
      "         -1.4830e-26,  1.9419e-08,  1.5216e-02,  1.2084e-16, -6.6677e-07],\n",
      "        [-4.2517e-18, -1.1374e-05,  3.0129e-22,  2.9785e-03,  4.4054e-03,\n",
      "          4.2271e-06, -2.6282e-03, -6.5993e-05, -1.1290e-19, -1.1244e-21,\n",
      "          6.5165e-25, -1.4030e-02,  2.3171e-12, -3.5898e-03, -5.7323e-04,\n",
      "         -7.0860e-03,  9.9136e-03, -1.7048e-02,  3.2632e-03,  3.0684e-25],\n",
      "        [ 1.6582e-02,  5.4518e-01, -2.7264e-01,  3.2027e-01,  2.6994e-01,\n",
      "         -3.9299e-01, -1.2599e-01,  1.3550e-01, -7.0378e-02, -8.3342e-02,\n",
      "         -1.8611e-01, -3.7447e-02, -1.8575e-01,  3.9740e-01,  4.5464e-01,\n",
      "         -3.1381e-01, -4.2076e-01,  3.1314e-01, -2.9442e-01,  5.8131e-02],\n",
      "        [ 7.0165e-03, -5.4092e-01, -1.5441e-01,  2.8029e-01,  6.1211e-01,\n",
      "         -1.1849e-01, -1.0375e-01,  7.4326e-02, -1.0865e-02, -1.5331e-01,\n",
      "         -4.4562e-01,  1.5007e-02, -1.2685e-01, -1.7658e-02, -7.6458e-02,\n",
      "         -2.6784e-01, -7.3871e-02, -3.7681e-01, -1.3406e-01,  3.7321e-02],\n",
      "        [ 2.7166e-01,  6.9940e-01, -1.4679e-01, -4.0681e-01, -3.8095e-01,\n",
      "         -3.0070e-01, -4.1027e-01, -1.5382e-01, -4.7206e-01, -5.1108e-01,\n",
      "         -5.2101e-01, -2.4914e-01, -3.5247e-01,  1.7665e-01,  4.5121e-01,\n",
      "         -3.3867e-01, -2.0460e-01,  4.6494e-01, -2.6375e-01, -1.2864e-01],\n",
      "        [ 4.2072e-04, -9.9122e-03, -5.2935e-24,  1.0892e-02,  4.7478e-22,\n",
      "          1.1400e-15, -2.0840e-04, -9.2185e-26, -4.6367e-25,  1.1399e-17,\n",
      "          6.8196e-08,  9.7266e-03, -3.6068e-03, -2.0387e-25, -2.0733e-05,\n",
      "         -4.8349e-03,  1.0805e-24, -1.0631e-02,  1.6046e-03,  5.1562e-24]])\n",
      "gcn_layer_2.b Parameter containing:\n",
      "tensor([ 0.6539, -0.6428, -0.6775,  0.0707,  0.6123, -0.5534, -0.5405, -1.0438,\n",
      "         0.7357,  0.6669, -0.6607, -0.8821,  0.6483, -0.5890, -0.5784,  0.7176,\n",
      "         0.8768, -0.6529, -0.9125, -0.8154])\n",
      "gcn_layer_3.W Parameter containing:\n",
      "tensor([[-5.1518e-02, -4.3638e-02, -3.8735e-02, -3.2568e-02, -4.7788e-02,\n",
      "         -2.9730e-02, -2.4112e-02, -3.2689e-02, -8.6027e-03,  6.7482e-02,\n",
      "         -3.7429e-02, -5.4472e-02, -5.7986e-03,  1.2471e-02, -1.0750e-03,\n",
      "         -6.8816e-03, -2.4329e-02, -3.0774e-02,  3.6812e-03, -3.7892e-02],\n",
      "        [-6.3411e-01,  2.0469e-01, -6.6855e-01, -5.3758e-01, -2.1901e-01,\n",
      "         -5.1851e-01, -2.4560e-01, -2.3430e-02, -5.3557e-01,  3.9501e-01,\n",
      "         -3.9344e-01, -4.9599e-01,  3.2451e-01,  4.6334e-01,  2.3322e-01,\n",
      "         -5.0512e-01, -8.6770e-01, -5.6977e-01, -7.8669e-01, -3.6230e-01],\n",
      "        [-7.5264e-20, -2.3220e-02,  1.5487e-02,  1.9915e-03, -2.4954e-02,\n",
      "         -1.8415e-04,  3.0384e-05, -5.1436e-08,  7.4827e-24, -3.1845e-05,\n",
      "          4.7433e-03, -2.3468e-04,  1.7183e-02,  4.8611e-09,  3.3702e-19,\n",
      "          4.3261e-03,  6.4452e-22, -4.0729e-04, -2.1559e-15,  2.9074e-02],\n",
      "        [ 5.3592e-01, -3.5593e-01,  3.4724e-01,  7.5659e-01,  7.3697e-01,\n",
      "          6.6109e-01,  6.8277e-01,  6.3853e-01,  5.7885e-01, -8.0914e-01,\n",
      "          6.1460e-01,  7.3311e-01, -1.9408e-01, -3.1664e-01, -6.4734e-01,\n",
      "          7.3850e-01,  6.4622e-01,  5.9864e-01,  3.7372e-01,  6.2178e-01],\n",
      "        [ 1.2614e+00, -5.3278e-01,  6.6076e-01,  1.0731e+00,  7.0142e-01,\n",
      "          1.2689e+00,  4.4189e-01,  6.7818e-01,  4.4623e-01, -1.1161e+00,\n",
      "          8.9626e-01,  1.2680e+00, -5.7501e-01, -2.3096e-01, -8.3671e-01,\n",
      "          1.1604e+00,  1.2000e+00,  1.2001e+00,  6.8078e-01,  1.2687e+00],\n",
      "        [ 3.4288e-04, -6.0965e-06, -9.0340e-06, -7.5611e-03,  6.1568e-18,\n",
      "         -5.8505e-03,  6.5563e-07,  7.6193e-12, -9.7169e-03,  1.3132e-15,\n",
      "          9.3074e-25,  3.8112e-06,  1.7109e-04, -2.2749e-02,  1.3945e-02,\n",
      "          7.5542e-03,  1.3606e-07, -1.3640e-02, -3.9757e-09,  3.4941e-14],\n",
      "        [ 7.5977e-17,  1.3505e-04,  7.6621e-09,  4.8895e-03, -2.1414e-08,\n",
      "          3.0994e-10,  3.4075e-09, -7.1625e-03, -1.9713e-02, -3.8964e-05,\n",
      "          1.3268e-03, -1.6450e-02, -9.8441e-03,  1.2315e-04,  7.1420e-05,\n",
      "          6.5334e-03, -3.2845e-03, -2.5020e-03,  3.2345e-05,  9.7813e-03],\n",
      "        [-7.6641e-01,  4.5849e-01, -7.5247e-01, -6.2313e-01, -6.5164e-01,\n",
      "         -8.6256e-01, -4.9558e-01, -5.2541e-01, -3.7590e-01,  7.2799e-01,\n",
      "         -7.3769e-01, -8.1450e-01,  5.3427e-01,  5.2200e-01,  5.1123e-01,\n",
      "         -7.4376e-01, -8.6429e-01, -7.2401e-01, -6.4312e-01, -5.8710e-01],\n",
      "        [-2.0715e-05, -7.8435e-19, -7.5482e-16, -7.9482e-04, -2.1096e-02,\n",
      "          1.3481e-04, -3.3873e-17, -1.5930e-02, -6.9398e-04,  2.1999e-02,\n",
      "          4.1290e-08,  1.7208e-07, -2.9414e-04, -1.5676e-06,  5.7560e-23,\n",
      "         -5.6048e-23, -1.3404e-03,  8.7424e-25, -4.1923e-25, -8.5200e-24],\n",
      "        [-1.0346e-23, -1.2195e-07, -1.3969e-16,  2.6912e-08, -4.9454e-05,\n",
      "         -2.2414e-02,  4.4787e-05, -9.3782e-19, -2.8041e-05,  1.8961e-02,\n",
      "         -3.0896e-06,  1.1642e-03,  2.6899e-05, -7.5388e-03,  7.0978e-04,\n",
      "         -1.4178e-02, -1.0525e-04,  1.8814e-22, -1.1346e-03,  2.0554e-02],\n",
      "        [ 8.7296e-21,  2.4437e-07, -1.1149e-02,  2.5466e-04, -2.1460e-09,\n",
      "         -4.0208e-03,  1.4639e-19,  3.3400e-05,  9.4657e-03, -4.6735e-04,\n",
      "         -2.6206e-05,  8.8121e-18,  2.5790e-09,  6.4975e-07,  9.3997e-05,\n",
      "          2.4456e-17,  1.1677e-04,  3.3173e-03, -7.9366e-16,  4.0434e-03],\n",
      "        [ 1.3962e-05,  1.0781e-02, -1.5011e-04, -1.6888e-05,  2.9178e-14,\n",
      "          6.0203e-25,  3.0599e-04, -1.5968e-04,  2.1474e-05, -4.4989e-09,\n",
      "          3.3157e-04,  4.5963e-25, -1.0293e-02, -9.5409e-05, -2.2604e-03,\n",
      "          1.8233e-05, -1.0754e-03, -1.5406e-24, -6.7956e-20, -9.0857e-05],\n",
      "        [-2.4017e-14, -2.0494e-02, -2.0335e-03, -1.2899e-02,  6.4395e-14,\n",
      "         -8.2345e-09, -4.1671e-24, -1.5670e-21,  6.7688e-06,  1.3915e-02,\n",
      "          4.6976e-09, -1.0256e-07, -1.5907e-02,  6.6790e-09, -1.7910e-05,\n",
      "          2.8307e-05,  1.0416e-03,  5.4678e-08,  1.6111e-02,  1.7366e-02],\n",
      "        [ 3.2337e-19, -5.7256e-03,  1.8821e-02, -1.4803e-03, -5.6802e-04,\n",
      "          8.8574e-03,  8.9768e-03,  1.4251e-05,  6.8495e-25, -1.0432e-02,\n",
      "          7.2183e-15,  2.5755e-02,  9.2659e-05,  4.5358e-08, -1.7948e-19,\n",
      "         -5.3450e-06,  3.3895e-04,  7.8267e-09,  1.7733e-03, -7.4094e-04],\n",
      "        [-1.2199e-02,  2.6193e-01, -1.6594e-02,  2.5111e-01,  2.6285e-01,\n",
      "          3.7098e-01,  3.3317e-01, -1.5288e-01, -2.9548e-01,  1.2310e-01,\n",
      "          3.7159e-03, -1.7565e-01, -4.8605e-02,  4.7710e-02,  4.3699e-01,\n",
      "          4.9425e-02, -3.1371e-01, -2.9899e-01, -2.4773e-01, -2.5580e-01],\n",
      "        [ 1.2267e-02,  5.3881e-05,  1.2608e-02, -2.3129e-26,  1.2784e-20,\n",
      "          1.1992e-09, -1.7006e-02,  1.4457e-24,  4.2509e-25, -1.2455e-04,\n",
      "         -4.1355e-03,  1.1051e-02,  5.9914e-03,  5.1151e-06,  1.7867e-02,\n",
      "         -2.3421e-07, -4.8978e-22,  3.0539e-08,  2.5031e-22,  7.1398e-21],\n",
      "        [-6.7859e-03,  3.3858e-16, -3.3304e-04, -3.3032e-25,  2.0316e-02,\n",
      "         -7.1286e-13, -6.5978e-12,  3.2623e-04, -1.1401e-08,  1.7031e-24,\n",
      "          1.5628e-02, -3.0719e-07, -2.0309e-03, -1.2145e-04, -2.7112e-15,\n",
      "         -8.1084e-06, -3.9015e-05,  2.0681e-07,  2.8531e-22, -1.9278e-11],\n",
      "        [-8.3263e-01,  4.0889e-02, -4.2199e-01, -3.6737e-01, -5.9930e-01,\n",
      "         -6.8563e-02, -4.8681e-01, -5.2570e-01, -4.2964e-01,  3.7773e-01,\n",
      "         -3.2092e-01, -3.9776e-01,  4.8409e-01,  3.2047e-01,  5.9585e-01,\n",
      "         -7.1189e-01, -7.2632e-01, -4.4686e-01,  1.2279e-01, -1.3611e-01],\n",
      "        [-3.0292e-03,  5.3561e-26, -4.1672e-03, -7.2753e-20, -2.1289e-15,\n",
      "          9.4750e-03,  1.4450e-12, -2.5423e-22,  1.1586e-22,  2.5465e-14,\n",
      "          9.4798e-08,  1.1522e-07,  3.1813e-16, -7.4951e-08,  8.5502e-03,\n",
      "         -2.1248e-23, -7.2358e-08,  5.0988e-04,  6.1044e-03,  2.2882e-02],\n",
      "        [-1.1246e-13, -5.6574e-10,  2.7405e-05,  8.8980e-03, -2.1042e-02,\n",
      "         -4.5392e-24, -1.2774e-03,  2.4298e-21,  3.8575e-07, -1.6012e-20,\n",
      "         -1.3225e-24,  2.7943e-06,  2.3678e-23, -7.6294e-03,  5.2914e-03,\n",
      "         -2.3516e-05, -2.2289e-24,  2.1975e-24,  4.8156e-25, -1.6366e-02]])\n",
      "gcn_layer_3.b Parameter containing:\n",
      "tensor([ 0.3259,  1.0564,  0.5853, -0.5053, -0.0632, -0.8088, -0.5331,  0.0761,\n",
      "        -0.1702, -0.7556,  0.7699,  0.4781,  0.3579, -0.5029,  0.8105, -0.4080,\n",
      "         0.3398, -0.4864, -0.7166, -0.3036])\n",
      "linear_layer.weight Parameter containing:\n",
      "tensor([[ 1.7839e-01,  1.5046e-01, -3.1510e-01,  2.0634e-01, -3.5574e-01,\n",
      "          1.5237e-01, -3.9669e-01, -1.9474e-01, -4.0607e-01,  9.6530e-02,\n",
      "         -1.8230e-01, -2.5174e-02, -2.6844e-01, -2.3361e-01,  1.9938e-01,\n",
      "          2.4745e-01, -3.9595e-01,  1.7697e-01, -1.1698e-01,  2.8799e-01,\n",
      "         -2.2768e-01, -1.7587e-01,  2.8931e-01, -7.4624e-01, -3.3528e-01,\n",
      "          9.0078e-02,  1.7693e-01, -2.2097e-01,  2.6366e-01,  2.9741e-01,\n",
      "          6.4123e-01, -3.9638e-02,  2.2414e-01, -1.5806e-01, -1.7266e-01,\n",
      "          3.8941e-01,  2.7083e-01, -2.4439e-01,  1.2147e-01,  6.6617e-02,\n",
      "         -4.7793e-01,  4.1345e-01, -2.1098e-01, -5.1866e-01, -3.7311e-01,\n",
      "         -6.1280e-01, -2.8588e-01, -1.8274e-01, -1.3155e-01,  3.0747e-01,\n",
      "         -1.7920e-01, -3.7578e-01,  1.1622e-01,  7.7170e-02,  3.6942e-01,\n",
      "         -3.4123e-01, -2.8183e-01, -3.5288e-01, -3.1227e-01, -6.0013e-01],\n",
      "        [-4.4533e-01,  7.8756e-02,  5.4724e-01,  1.4785e-01,  1.4737e-01,\n",
      "          9.2757e-02,  4.1327e-01,  1.0058e+00,  6.0465e-01, -5.7830e-02,\n",
      "          5.0390e-01, -2.4355e-01,  2.7412e-01,  1.1565e+00, -4.5600e-01,\n",
      "         -7.6703e-02,  3.9166e-01, -1.0969e+00,  1.9319e-01, -3.0985e-01,\n",
      "         -6.7503e-01,  3.2487e-01,  5.5221e-02,  2.9968e-01, -8.9911e-01,\n",
      "          9.8575e-02,  1.2423e-01,  1.0078e+00, -4.7078e-01, -6.6080e-01,\n",
      "          2.0469e-01,  4.5249e-01, -4.7413e-01,  8.6152e-01,  4.2979e-01,\n",
      "         -3.7608e-01, -5.6014e-01,  4.6242e-01,  5.2760e-01,  2.8550e-01,\n",
      "          7.6904e-02, -7.1993e-01, -1.1087e-01,  6.1416e-01,  1.6911e-01,\n",
      "          7.7256e-01,  4.0486e-01,  1.2517e-01,  1.0541e-01,  1.6481e-01,\n",
      "         -2.3258e-01, -4.9124e-02, -2.4150e-01,  1.6894e-01, -4.1036e-01,\n",
      "          3.6376e-01,  5.8151e-02,  4.1590e-01,  5.0300e-01,  4.6603e-01],\n",
      "        [-1.7815e-01, -5.5920e-01,  3.9512e-01, -5.1809e-01,  5.8652e-01,\n",
      "         -6.0008e-01,  5.3074e-01, -4.3400e-01,  5.4446e-01, -2.8025e-01,\n",
      "          2.4446e-01,  4.7887e-03,  3.6818e-01, -7.1328e-01, -2.0185e-01,\n",
      "         -4.5386e-01,  4.6313e-01,  7.5609e-01,  2.6982e-01, -4.9959e-01,\n",
      "          6.4208e-01,  7.7435e-02, -4.4381e-01,  7.6185e-01,  9.5692e-01,\n",
      "         -2.8335e-01, -3.1228e-01, -4.8415e-01, -1.5703e-01, -3.4215e-01,\n",
      "         -7.9527e-01, -1.5915e-01, -2.4798e-01, -2.7160e-01,  1.2482e-01,\n",
      "         -2.4763e-01, -3.2483e-02,  2.4937e-01, -4.4643e-01, -1.5964e-01,\n",
      "          5.6600e-01,  3.5045e-02,  5.1106e-01,  6.6640e-01,  3.4734e-01,\n",
      "          6.1719e-01,  2.6134e-01,  3.4272e-01,  1.8863e-01, -6.0590e-01,\n",
      "          5.3339e-01,  5.2260e-01, -3.2092e-01, -3.0889e-01, -1.4361e-01,\n",
      "          5.1679e-01,  5.1229e-01,  4.3454e-01,  3.6112e-01,  5.2242e-01],\n",
      "        [ 1.1430e-01, -4.6250e-02, -2.1695e-01, -1.6267e-01,  1.0074e-03,\n",
      "         -1.3009e-01, -1.5626e-01, -3.2036e-01, -1.3298e-01,  8.7358e-02,\n",
      "         -1.1552e-01,  1.3541e-01,  5.6157e-02, -5.9773e-01, -1.0289e-02,\n",
      "         -1.0884e-01, -2.1983e-01,  6.7657e-01, -5.3876e-02, -2.9140e-03,\n",
      "          5.7218e-02, -7.4361e-02, -6.4421e-01,  2.4916e-01,  2.5859e-01,\n",
      "         -1.5222e-01, -1.1588e-02, -2.3253e-01,  1.3677e-01,  1.5723e-01,\n",
      "         -6.1845e-01, -1.5888e-01,  9.4471e-02, -3.8775e-01, -7.8914e-02,\n",
      "          9.3742e-02,  1.8869e-01, -5.9731e-03, -2.1270e-01, -1.3067e-01,\n",
      "          1.3783e-01,  6.0868e-01,  1.5758e-01,  4.8093e-02,  1.6689e-01,\n",
      "         -1.4245e-01,  3.1648e-02,  1.8045e-01,  3.5741e-02, -4.0290e-01,\n",
      "          2.7852e-01,  2.4311e-01,  6.8893e-02, -2.8910e-02,  1.9355e-01,\n",
      "         -8.1362e-03,  7.4571e-02,  2.8132e-02, -1.2322e-01,  1.9978e-01]])\n",
      "linear_layer.bias Parameter containing:\n",
      "tensor([ 0.0087, -0.6557,  0.5182,  0.2225])\n"
     ]
    }
   ],
   "source": [
    "for name, i in a.named_parameters():\n",
    "    print(name, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42b8b5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7221e-01, -9.9564e-01,  6.1275e-01,  6.6902e-01,  6.3763e-01],\n",
       "        [ 8.2925e-01,  3.6445e-02,  2.3564e-01, -9.5389e-02,  9.9063e-01],\n",
       "        [ 8.8164e-02, -2.0913e-01,  8.9743e-03,  8.9303e-01,  5.0054e-02],\n",
       "        [-6.4884e-01, -4.8470e-04,  8.4469e-01,  4.0266e-01, -7.2459e-01],\n",
       "        [-2.4416e-01, -4.3232e-01, -4.3121e-01,  3.8157e-01, -5.8365e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.FloatTensor(5,5).uniform_(-1, 1)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24a9b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = torch.sigmoid(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98b86d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = (pert > 0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eb8fd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a7b364e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.7221e-01, -9.9564e-01,  6.1275e-01,  6.6902e-01,  6.3763e-01],\n",
       "        [ 8.2925e-01,  3.6445e-02,  2.3564e-01, -9.5389e-02,  9.9063e-01],\n",
       "        [ 8.8164e-02, -2.0913e-01,  8.9743e-03,  8.9303e-01,  5.0054e-02],\n",
       "        [-6.4884e-01, -4.8470e-04,  8.4469e-01,  4.0266e-01, -7.2459e-01],\n",
       "        [-2.4416e-01, -4.3232e-01, -4.3121e-01,  3.8157e-01, -5.8365e-01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "270ca811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 2.,  6.,  7.,  8.,  9.],\n",
       "        [ 3.,  7., 10., 11., 12.],\n",
       "        [ 4.,  8., 11., 13., 14.],\n",
       "        [ 5.,  9., 12., 14., 15.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "vals = torch.arange(N*(N+1)/2) + 1\n",
    " \n",
    "A = torch.zeros(N, N)\n",
    "i, j = torch.triu_indices(N, N)\n",
    "A[i, j] = vals\n",
    "A.T[i, j] = vals\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173dab6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  4.,  7., 11.],\n",
       "        [ 2.,  3.,  5.,  8., 12.],\n",
       "        [ 4.,  5.,  6.,  9., 13.],\n",
       "        [ 7.,  8.,  9., 10., 14.],\n",
       "        [11., 12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.zeros(N, N)\n",
    "idx = torch.tril_indices(N, N)\n",
    "matrix[idx[0], idx[1]] = vals\n",
    "symm_matrix = torch.tril(matrix) + torch.tril(matrix, -1).t()\n",
    "symm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2c2a33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
       "        15.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0295c52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 2.,  6.,  7.,  8.,  9.],\n",
       "        [ 3.,  7., 10., 11., 12.],\n",
       "        [ 4.,  8., 11., 13., 14.],\n",
       "        [ 5.,  9., 12., 14., 15.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e425dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26cf717a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bc2bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28626143175.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=239274\n",
    "N*(N+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92442888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1.],\n",
       "        [1., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26e1d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 0,  1, 0], [0, 0, 0, 0], [1, 0,  0, 1], [0, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42fc3c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 1, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 0, 1, 1]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "200c416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a subgraph neighbourhood for vertex 1\n",
    "vertices = set([0])\n",
    "edges = set([])\n",
    "k_hops = 3\n",
    "labels = [1, 2, 3, 4]\n",
    "features = [[0,0], [1, 1], [2,2], [3,3]]\n",
    "\n",
    "for hop in range(k_hops): # loop over the set amount of hops\n",
    "    for vertex_1 in list(vertices): # loop over all vertices already in the set --> this is the column we're in\n",
    "        for vertex_2 in range(a.shape[0]): # loop over every connection of a certain vertex --> this is the row we're in\n",
    "            if a[vertex_2, vertex_1].data == 1:\n",
    "                vertices.add(vertex_2) # add the vertex if there is a connection\n",
    "                edges.add((vertex_2, vertex_1)) # add the edge if it exists\n",
    "                \n",
    "# create the adjacency matrix:\n",
    "adj = torch.zeros(len(vertices), len(vertices))\n",
    "\n",
    "# perform a certain mapping:\n",
    "vertex_list = list(vertices)\n",
    "vertex_list.sort()\n",
    "vertex_indices = range(len(vertices))\n",
    "vertex_mapping = {}\n",
    "\n",
    "for vertex in range(len(vertex_list)):\n",
    "    vertex_mapping[vertex_list[vertex]] = vertex_indices[vertex]\n",
    "    \n",
    "# fill new adjacency matrix\n",
    "for edge in edges:\n",
    "    edge_head = vertex_mapping[edge[0]]\n",
    "    edge_tail = vertex_mapping[edge[1]]\n",
    "    adj[edge_head][edge_tail] = 1\n",
    "\n",
    "# get new labels (slice)\n",
    "labels = labels[vertex_list]\n",
    "\n",
    "# get new features (slice)\n",
    "features = features[vertex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3fd17588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0a0b2ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 2: 1, 3: 2}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "061e4bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 4])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [1, 2, 3, 4]\n",
    "torch.tensor(labels)[vertex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4defc585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0], [2, 2], [3, 3]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d0afff05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.],\n",
       "        [1., 0., 1.],\n",
       "        [0., 1., 1.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8184abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2dd3dbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0), (0, 2), (2, 0), (2, 3), (3, 2), (3, 3)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e64286e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.],\n",
       "        [1., 1., 1., ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b76d401",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39msqueeze(data_syn1)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m][vertex] \u001b[38;5;28;01mfor\u001b[39;00m vertex \u001b[38;5;129;01min\u001b[39;00m vertex_list]\n",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_syn1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[vertex] \u001b[38;5;28;01mfor\u001b[39;00m vertex \u001b[38;5;129;01min\u001b[39;00m vertex_list]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "features = [np.squeeze(data_syn1)['feat'][vertex] for vertex in vertex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4dc2e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.squeeze(data_syn1['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "88129fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[vertex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14335c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import NLLLoss\n",
    "\n",
    "def loss_function(beta, output_g, predictions_original, predictions_perturbed, adjacency_matrix_original, perturbation_matrix):\n",
    "    \n",
    "    # find nll loss using the output and the predictions\n",
    "    nll_loss_part = NLLLoss(F.log_softmax(output_g, dim=1), target=predictions_original)\n",
    "    loss_pred = - (predictions_original == predictions_perturbed).float() * nll_loss_part\n",
    "    \n",
    "    # get the new adjacency matrix --> needs grad for loss dist to have a grad\n",
    "    adjacency_matrix_perturbed = torch.mul(adjacency_matrix_original, perturbation_matrix)\n",
    "    adjacency_matrix_perturbed.requires_grad = True\n",
    "    \n",
    "    # count the number of times the adjacency matrix is different --> divide by 2 (because symmetric)\n",
    "    loss_dist = torch.sum((adjacency_matrix_perturbed == adjacency_matrix_original).float()).data / 2\n",
    "    \n",
    "    return loss_pred + beta * loss_dist, adjacency_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f247247",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 0], [0, 1]])\n",
    "b = torch.tensor([[1, 1],[0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "23953c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5500, 0.4800],\n",
       "        [0.1300, 0.2800]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "884ebcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.4000],\n",
       "        [0.1000, 0.2000]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "be3eff9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ca38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janneke/opt/anaconda3/envs/CF-GNNExplainer/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "with open('data/syn1.pickle','rb') as pickle_file: \n",
    "    data_syn1 = pickle.load(pickle_file)\n",
    "\n",
    "with open('data/syn4.pickle','rb') as pickle_file:\n",
    "    data_syn4 = pickle.load(pickle_file)\n",
    "    \n",
    "with open('data/syn5.pickle','rb') as pickle_file:\n",
    "    data_syn5 = pickle.load(pickle_file)\n",
    "    \n",
    "test_indices_syn1 = torch.tensor(data_syn1['test_idx'])\n",
    "print(len(test_indices_syn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba56d245",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# squeeze the labels (as it has a singleton dim and then make it a tensor)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m labels_syn1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(data_syn1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m labels_syn1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(labels_syn1)\n\u001b[1;32m      5\u001b[0m labels_syn4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(data_syn4[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# squeeze the labels (as it has a singleton dim and then make it a tensor)\n",
    "labels_syn1 = np.squeeze(data_syn1['labels'])\n",
    "labels_syn1 = torch.tensor(labels_syn1)\n",
    "\n",
    "labels_syn4 = np.squeeze(data_syn4['labels'])\n",
    "labels_syn4 = torch.tensor(labels_syn4)\n",
    "\n",
    "labels_syn5 = np.squeeze(data_syn5['labels'])\n",
    "labels_syn5 = torch.tensor(labels_syn5)\n",
    "\n",
    "# same for features, but define the type of data here\n",
    "features_syn1 = np.squeeze(data_syn1['feat'])\n",
    "features_syn1 = torch.tensor(features_syn1, dtype=torch.float)\n",
    "\n",
    "features_syn4 = np.squeeze(data_syn4['feat'])\n",
    "features_syn4 = torch.tensor(features_syn4, dtype=torch.float)\n",
    "\n",
    "features_syn5 = np.squeeze(data_syn5['feat'])\n",
    "features_syn5 = torch.tensor(features_syn5, dtype=torch.float)\n",
    "\n",
    "# adjacency matrix will be turned into a tensor later on\n",
    "adjacency_matrix_syn1 = np.squeeze(data_syn1['adj'])\n",
    "adjacency_matrix_syn4 = np.squeeze(data_syn4['adj'])\n",
    "adjacency_matrix_syn5 = np.squeeze(data_syn5['adj'])\n",
    "\n",
    "# the indices are already a list --> but have to split the training data in training and validation data first\n",
    "train_indices_full_syn1 = torch.tensor(data_syn1['train_idx'])\n",
    "train_indices_full_syn4 = torch.tensor(data_syn4['train_idx'])\n",
    "train_indices_full_syn5 = torch.tensor(data_syn5['train_idx'])\n",
    "\n",
    "# split in training and validation indices\n",
    "train_indices_syn1, validation_indices_syn1 = torch.utils.data.random_split(train_indices_full_syn1, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "train_indices_syn4, validation_indices_syn4 = torch.utils.data.random_split(train_indices_full_syn4, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "train_indices_syn5, validation_indices_syn5 = torch.utils.data.random_split(train_indices_full_syn5, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "test_indices_syn1 = torch.tensor(data_syn1['test_idx'])\n",
    "test_indices_syn4 = torch.tensor(data_syn4['test_idx'])\n",
    "test_indices_syn5 = torch.tensor(data_syn5['test_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ea5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a subgraph neighbourhood for vertex 1\n",
    "a = adjacency_matrix_syn5\n",
    "vertices = set([1])\n",
    "edges = set([])\n",
    "k_hops = 3\n",
    "labels = labels_syn5 # [1, 2, 3, 4]\n",
    "features = features_syn5 #[[0,0], [1, 1], [2,2], [3,3]]\n",
    "\n",
    "for hop in range(k_hops): # loop over the set amount of hops\n",
    "    for vertex_1 in list(vertices): # loop over all vertices already in the set --> this is the column we're in\n",
    "        for vertex_2 in range(a.shape[0]): # loop over every connection of a certain vertex --> this is the row we're in\n",
    "            if a[vertex_2, vertex_1] == 1:\n",
    "                vertices.add(vertex_2) # add the vertex if there is a connection\n",
    "                edges.add((vertex_2, vertex_1)) # add the edge if it exists\n",
    "                \n",
    "# create the adjacency matrix:\n",
    "adj = torch.zeros(len(vertices), len(vertices))\n",
    "\n",
    "# perform a certain mapping:\n",
    "vertex_list = list(vertices)\n",
    "vertex_list.sort()\n",
    "vertex_indices = range(len(vertices))\n",
    "vertex_mapping = {}\n",
    "\n",
    "for vertex in range(len(vertex_list)):\n",
    "    vertex_mapping[vertex_list[vertex]] = vertex_indices[vertex]\n",
    "    \n",
    "# fill new adjacency matrix\n",
    "for edge in edges:\n",
    "    edge_head = vertex_mapping[edge[0]]\n",
    "    edge_tail = vertex_mapping[edge[1]]\n",
    "    adj[edge_head][edge_tail] = 1\n",
    "\n",
    "# get new labels (slice)\n",
    "labels = labels[vertex_list]\n",
    "\n",
    "# get new features (slice)\n",
    "features = features[vertex_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905d5f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 36,\n",
       " 51,\n",
       " 73,\n",
       " 74,\n",
       " 104,\n",
       " 149,\n",
       " 150,\n",
       " 209,\n",
       " 210,\n",
       " 267,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 511,\n",
       " 512,\n",
       " 514,\n",
       " 565,\n",
       " 736,\n",
       " 788,\n",
       " 1153}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7b7c97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 2,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 6,\n",
       " 7: 7,\n",
       " 8: 8,\n",
       " 9: 9,\n",
       " 10: 10,\n",
       " 15: 11,\n",
       " 16: 12,\n",
       " 17: 13,\n",
       " 18: 14,\n",
       " 19: 15,\n",
       " 20: 16,\n",
       " 21: 17,\n",
       " 22: 18,\n",
       " 36: 19,\n",
       " 51: 20,\n",
       " 73: 21,\n",
       " 74: 22,\n",
       " 104: 23,\n",
       " 149: 24,\n",
       " 150: 25,\n",
       " 209: 26,\n",
       " 210: 27,\n",
       " 267: 28,\n",
       " 299: 29,\n",
       " 300: 30,\n",
       " 301: 31,\n",
       " 302: 32,\n",
       " 511: 33,\n",
       " 512: 34,\n",
       " 514: 35,\n",
       " 565: 36,\n",
       " 736: 37,\n",
       " 788: 38,\n",
       " 1153: 39}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertex_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "569e4779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c6dbb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78010e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether the results are the same!\n",
    "wrong = 0\n",
    "right = 0\n",
    "for index in range(len(labels_syn5)):\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index, 4, labels_syn5, features_syn5, adjacency_matrix_syn5)\n",
    "\n",
    "    # gets the same outcome\n",
    "    with torch.no_grad():\n",
    "        sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    outputs_test = model_syn5(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # print accuracy too (to check that it is the same as in the original)\n",
    "    _, predictions_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    if predictions_test[vertex_mapping[index]] == predictions_5[index]:\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print(right)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83980e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether the results are the same!\n",
    "wrong = 0\n",
    "right = 0\n",
    "for index in range(len(labels_syn4)):\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index, 4, labels_syn4, features_syn4, adjacency_matrix_syn4)\n",
    "\n",
    "    # gets the same outcome\n",
    "    sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model_syn4(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # print accuracy too (to check that it is the same as in the original)\n",
    "    \n",
    "    if predictions_test[vertex_mapping[index]] == predictions_4[index]:\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print(right)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph, dense_to_sparse, to_dense_adj, subgraph\n",
    "\n",
    "\n",
    "adj = torch.Tensor(data_syn5[\"adj\"]).squeeze()       # Does not include self loops\n",
    "features = torch.Tensor(data_syn5[\"feat\"]).squeeze()\n",
    "labels = torch.tensor(data_syn5[\"labels\"]).squeeze()\n",
    "idx_train = torch.tensor(data_syn5[\"train_idx\"])\n",
    "idx_test = torch.tensor(data_syn5[\"test_idx\"])\n",
    "edge_index = dense_to_sparse(adj)    \n",
    "n_layers=3\n",
    "\n",
    "# for testing\n",
    "def get_neighbourhood(node_idx, edge_index, n_hops, features, labels):\n",
    "    edge_subset = k_hop_subgraph(node_idx, n_hops, edge_index[0])     # Get all nodes involved\n",
    "    edge_subset_relabel = subgraph(edge_subset[0], edge_index[0], relabel_nodes=True)       # Get relabelled subset of edges\n",
    "    sub_adj = to_dense_adj(edge_subset_relabel[0]).squeeze()\n",
    "    sub_feat = features[edge_subset[0], :]\n",
    "    sub_labels = labels[edge_subset[0]]\n",
    "    new_index = np.array([i for i in range(len(edge_subset[0]))])\n",
    "    node_dict = dict(zip(edge_subset[0].numpy(), new_index))        # Maps orig labels to new\n",
    "    # print(\"Num nodes in subgraph: {}\".format(len(edge_subset[0])))\n",
    "    return sub_adj, sub_feat, sub_labels, node_dict\n",
    "\n",
    "\n",
    "correct = 0\n",
    "incorrect =0\n",
    "for i in range(len(labels_syn5)):\n",
    "    sub_adj, sub_feat, sub_labels, node_dict = get_neighbourhood(int(i), edge_index, n_layers + 1, features, labels)\n",
    "    new_idx = node_dict[int(i)]\n",
    "\n",
    "    # Check that original model gives same prediction on full graph and subgraph\n",
    "    with torch.no_grad():\n",
    "        #print(\"Output original model, full adj: {}\".format(predictions_1[i]))\n",
    "        #_, output = torch.max(model_syn1(sub_feat, normalize_adj(sub_adj)), dim=1)[new_idx]\n",
    "        a, b =  torch.max(torch.unsqueeze(model_syn5(sub_feat, get_sparse_adjacency_normalized(sub_feat.shape[0], sub_adj))[new_idx], dim=0), dim=1)\n",
    "        #print(\"Output original model, sub adj: {}\".format(torch.squeeze(b).data))\n",
    "        if b == predictions_5[i]:\n",
    "            correct+=1\n",
    "        elif b != predictions_5[i]:\n",
    "            incorrect+= 1\n",
    "\n",
    "print(correct)\n",
    "print(incorrect)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 633\n",
    "adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index, 4, labels_syn1, features_syn1, adjacency_matrix_syn1)\n",
    "adjacency_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph, dense_to_sparse, to_dense_adj, subgraph\n",
    "\n",
    "\n",
    "# for testing\n",
    "def get_neighbourhood(node_idx, edge_index, n_hops, features, labels):\n",
    "    edge_subset = k_hop_subgraph(node_idx, n_hops, edge_index[0])     # Get all nodes involved\n",
    "    edge_subset_relabel = subgraph(edge_subset[0], edge_index[0], relabel_nodes=True)       # Get relabelled subset of edges\n",
    "    sub_adj = to_dense_adj(edge_subset_relabel[0]).squeeze()\n",
    "    sub_feat = features[edge_subset[0], :]\n",
    "    sub_labels = labels[edge_subset[0]]\n",
    "    new_index = np.array([i for i in range(len(edge_subset[0]))])\n",
    "    node_dict = dict(zip(edge_subset[0].numpy(), new_index))        # Maps orig labels to new\n",
    "    # print(\"Num nodes in subgraph: {}\".format(len(edge_subset[0])))\n",
    "    return sub_adj, sub_feat, sub_labels, node_dict\n",
    "\n",
    "adj = torch.Tensor(data_syn1[\"adj\"]).squeeze()\n",
    "features = torch.Tensor(data_syn1[\"feat\"]).squeeze()\n",
    "labels = torch.tensor(data_syn1[\"labels\"]).squeeze()\n",
    "edge_index = dense_to_sparse(adj)   \n",
    "sub_adj, sub_feat, sub_labels, node_dict = get_neighbourhood(int(index), edge_index,  4, features, labels)\n",
    "new_idx = node_dict[int(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether the results are the same!\n",
    "wrong = 0\n",
    "right = 0\n",
    "for index in range(len(labels_syn4)):\n",
    "    adjacency_matrix, vertex_mapping, labels_perturbed, features_perturbed = create_subgraph_neighbourhood2(index, 4, labels_syn4, features_syn4, adjacency_matrix_syn4)\n",
    "\n",
    "    # gets the same outcome\n",
    "    sparse_adj_test = get_sparse_adjacency_normalized(features_perturbed.shape[0], adjacency_matrix)\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model_syn4(features_perturbed, sparse_adj_test)\n",
    "\n",
    "    # print accuracy too (to check that it is the same as in the original)\n",
    "    _, predictions_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    if predictions_test[vertex_mapping[index]].data == predictions_4[index].data:\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print(right)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb97c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cf_example(inx, pred_old, pert_model, optimizer, bet, k, adjacency_subgraph, labels_pert, features_pert):\n",
    "    best_cf = []  # list of best counterfactual examples thus far\n",
    "    train_loss = [] # list of all losses\n",
    "    current_best = torch.inf  # best loss thus far\n",
    "\n",
    "    for i in range(k):\n",
    "        # need to add more here if needed:\n",
    "        pert_matrix, prediction, loss = train_and_get_example(inx, pred_old, pert_model, optimizer, bet, adjacency_subgraph, features_pert)\n",
    "\n",
    "        if pred_old != prediction:  # if the prediction is different\n",
    "            if not best_cf:  # if it is empty!!\n",
    "                best_cf.append(pert_matrix)\n",
    "                current_best = loss\n",
    "            elif loss < current_best:\n",
    "                best_cf.append(pert_matrix)\n",
    "                current_best = loss\n",
    "                print(loss)\n",
    "                \n",
    "        train_loss.append(loss)\n",
    "\n",
    "    # return the list of all the best ones\n",
    "    return best_cf, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import nll_loss\n",
    "\n",
    "def train_and_get_example(inx, pred_old, pert_model, optimizer, bet, adjacency_subgraph, features_pert):\n",
    "    \n",
    "    # set optimizer to zero grad!\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # one forward step:\n",
    "    output = pert_model(features_pert, adjacency_subgraph)\n",
    "    output_perturbed, perturbation_matrix = pert_model.forward_binary(features_pert, adjacency_subgraph)\n",
    "    \n",
    "    # get the new prediction:\n",
    "    new_prediction = torch.argmax(output_perturbed[inx])\n",
    "    \n",
    "    # calculate the loss:\n",
    "    loss, perturbed_adj, loss_dist, loss_pred = loss_function(bet, output[inx], pred_old, new_prediction.item(), adjacency_subgraph, perturbation_matrix)\n",
    "    \n",
    "    # calculate the grad\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip the gradients\n",
    "    torch.nn.utils.clip_grad_norm_(pert_model.parameters(), 2.)\n",
    "    \n",
    "    # do a step with the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    return perturbation_matrix, new_prediction, loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CFGNNExplainerKernel",
   "language": "python",
   "name": "cfgnnexplainerkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
